{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7375642,"sourceType":"datasetVersion","datasetId":4285769},{"sourceId":3849,"sourceType":"modelInstanceVersion","modelInstanceId":2750,"modelId":324}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Zero-Shot Segmentation of Satellite Imagery for Deforestation Detection Using the Segment Anything Model (SAM)","metadata":{}},{"cell_type":"markdown","source":"## Intro","metadata":{}},{"cell_type":"markdown","source":"* **Objective**: This experiment aims to utilize the Segment Anything Model (SAM) for automatic segmentation of satellite imagery to identify deforestation areas. The focus is on generating accurate segmentation masks from satellite images in TIFF format.\n\n* **Dataset**: The dataset consists of multi-band satellite images (TIFF files) captured by the Sentinel-2 satellite. Each image is processed to extract the Red, Green, and Blue (RGB) bands, representing different spectral properties of the Earth's surface.\n\n* **Model**: The SAM model, specifically the vit_h (high-capacity version), is used for segmentation. Pre-trained on large-scale datasets, SAM can generate detailed and highly accurate segmentation masks without needing manual annotations.\n\n* **Process**: The experiment involves loading the satellite images, generating segmentation masks using SAM, and filtering the top 50 largest masks based on area. The results are visualized by overlaying the masks onto the original RGB images.\n \n* **Outcome**: By applying SAM, this experiment provides an automated, efficient way to detect and visualize potential deforestation regions, contributing to environmental monitoring and data-driven decision-making.","metadata":{}},{"cell_type":"markdown","source":"## Import Required Libraries\n\n- In this cell, we import all the necessary libraries, including PyTorch, Numpy, OpenCV, Matplotlib, Rasterio, and the segment-anything package, which contains the SAM model and utilities.","metadata":{}},{"cell_type":"code","source":"!pip install torch opencv-python rasterio\n!pip install git+https://github.com/facebookresearch/segment-anything.git\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport rasterio\nimport os\n\n# Import SAM (Segment Anything Model) components\nfrom segment_anything import SamAutomaticMaskGenerator, sam_model_registry","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:11:59.233350Z","iopub.execute_input":"2024-09-02T09:11:59.233764Z","iopub.status.idle":"2024-09-02T09:11:59.239410Z","shell.execute_reply.started":"2024-09-02T09:11:59.233722Z","shell.execute_reply":"2024-09-02T09:11:59.238469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Initialization\n\n- In this cell, we initialize the SAM model by loading its pre-trained weights, then set up the device (GPU or CPU) and allow for multi-GPU support.","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained SAM model\nsam_checkpoint = \"/kaggle/input/segment-anything/pytorch/vit-h/1/model.pth\"  # Path to SAM model checkpoint\nmodel_type = \"vit_h\"  # Choose SAM model type: vit_h, vit_l, or vit_b\n\n# Register the SAM model and load weights\nsam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n\n# Set up device (GPU if available, otherwise CPU)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Multi-GPU support using DataParallel (if you have multiple GPUs available)\nmodel = torch.nn.DataParallel(sam, device_ids=[0, 1]).to(device)\n\n# Initialize SAM's mask generator for automatic mask generation\nmask_generator = SamAutomaticMaskGenerator(sam)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:12:03.481133Z","iopub.execute_input":"2024-09-02T09:12:03.481570Z","iopub.status.idle":"2024-09-02T09:12:11.998147Z","shell.execute_reply.started":"2024-09-02T09:12:03.481528Z","shell.execute_reply":"2024-09-02T09:12:11.997380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to Clear GPU Memory\n\n- This cell defines a utility function that clears the GPU memory after each image is processed to avoid memory overflow issues.","metadata":{}},{"cell_type":"code","source":"# Function to clear GPU memory after each iteration\ndef clear_gpu_memory():\n    torch.cuda.empty_cache()  # Clears the PyTorch cache\n    for obj in list(locals().values()):\n        if torch.is_tensor(obj):\n            del obj  # Deletes any tensors still in memory\n    torch.cuda.empty_cache()  # Clears again after deletion","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:06:12.707329Z","iopub.execute_input":"2024-09-02T09:06:12.707645Z","iopub.status.idle":"2024-09-02T09:06:12.712758Z","shell.execute_reply.started":"2024-09-02T09:06:12.707610Z","shell.execute_reply":"2024-09-02T09:06:12.711902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Define Function for Image Processing and Mask Generation\n\n- This is where the main function is defined to handle the image processing and segmentation:","metadata":{}},{"cell_type":"code","source":"# Define a function to process TIFF images and generate segmentation masks\ndef process_tiff_and_generate_masks(tif_file, mask_generator):\n    print(f\"Processing: {tif_file}\")\n    \n    # Open the TIFF file and read the first three bands (R, G, B)\n    with rasterio.open(tif_file) as dataset:\n        r = dataset.read(1)  # Red channel\n        g = dataset.read(2)  # Green channel\n        b = dataset.read(3)  # Blue channel\n    \n    # Stack the R, G, B bands to create an RGB image\n    rgb_image = np.stack([r, g, b], axis=-1)\n    \n    # Normalize the RGB image to the range [0, 255] for visualization\n    rgb_image = (255 * (rgb_image - np.min(rgb_image)) / (np.max(rgb_image) - np.min(rgb_image))).astype(np.uint8)\n    \n    # Generate masks using the SAM mask generator\n    masks = mask_generator.generate(rgb_image)\n    \n    # Sort the masks by their area size and select the top 50 largest masks\n    sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n    top_masks = sorted_masks[:50]  # Limit to top 50 largest masks\n\n    return rgb_image, top_masks\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:13:14.194921Z","iopub.execute_input":"2024-09-02T09:13:14.195326Z","iopub.status.idle":"2024-09-02T09:13:14.203077Z","shell.execute_reply.started":"2024-09-02T09:13:14.195284Z","shell.execute_reply":"2024-09-02T09:13:14.202172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Visualization Function\n\n- This cell defines a function to visualize the original image and the generated segmentation masks side-by-side, then plots the results.","metadata":{}},{"cell_type":"code","source":"# Function to visualize the generated segmentation masks\ndef show_output(rgb_image, top_masks):\n    fig, axes = plt.subplots(1, 2, figsize=(16, 16))\n\n    # Display the original RGB image\n    axes[0].imshow(rgb_image)\n    axes[0].set_title(\"Original Image\")\n    axes[0].axis('off')  # Turn off the axes for a cleaner look\n\n    # Create an empty overlay image\n    overlay_image = np.zeros((rgb_image.shape[0], rgb_image.shape[1], 3))\n    \n    # Overlay the segmentation masks\n    for mask_info in top_masks:\n        mask = mask_info['segmentation']\n        color_mask = np.random.random(3)  # Random color for each mask\n        overlay_image[mask] = overlay_image[mask] * 0.5 + color_mask * 0.5\n    \n    # Display the segmentation masks overlay\n    axes[1].imshow(overlay_image)\n    axes[1].set_title(\"Segmentation Masks\")\n    axes[1].axis('off')\n\n    # Show the plot\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T10:21:18.140401Z","iopub.execute_input":"2024-09-19T10:21:18.141225Z","iopub.status.idle":"2024-09-19T10:21:18.148669Z","shell.execute_reply.started":"2024-09-19T10:21:18.141183Z","shell.execute_reply":"2024-09-19T10:21:18.147634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Call the Processing and Visualization Functions\n\n- Finally, we use the functions defined earlier to process the TIFF files and generate results:","metadata":{}},{"cell_type":"code","source":"# Path to the directory containing the TIFF images (deforestation dataset)\ndirectory = \"/kaggle/input/deforestation-detection-dataset/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/\"\n\n# Loop through the directory and process each .tif file\nfor filename in os.listdir(directory):\n    if filename.endswith(\".tif\"):  # Only process TIFF files\n        tif_file = os.path.join(directory, filename)\n        \n        # Process the image and generate masks\n        rgb_image, top_masks = process_tiff_and_generate_masks(tif_file, mask_generator)\n        \n        # Visualize the results\n        show_output(rgb_image, top_masks)\n        \n        # Clear GPU memory after processing each image\n        clear_gpu_memory()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:14:49.000785Z","iopub.execute_input":"2024-09-02T09:14:49.001184Z","iopub.status.idle":"2024-09-02T09:19:57.424741Z","shell.execute_reply.started":"2024-09-02T09:14:49.001146Z","shell.execute_reply":"2024-09-02T09:19:57.423853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\n\n# Define the corrected text data\ndata = \"\"\"\nMetric,Description,Image 1 Score (1-10),Image 2 Score (1-10),Image 3 Score (1-10),Image 4 Score (1-10),Image 5 Score (1-10),Image 6 Score (1-10),Image 7 Score (1-10),Image 8 Score (1-10),Image 9 Score (1-10),Image 10 Score (1-10)\nAccuracy,Measures the overall correctness of the segmentation.,8.5,8,7.5,7,7.5,7,6.5,6.5,7,6.5\nPrecision,Indicates how many of the predicted segments are relevant.,8,7.5,7,6.5,7,6.5,6,6,6.5,6\nRecall,Shows how many of the relevant segments are captured by the prediction.,9,8.5,8,7.5,8,7.5,7,7,7.5,7\nF1 Score,\\\"The harmonic mean of precision and recall, providing a balance between the two.\\\",8.5,8,7.5,7,7.5,7,6.5,6.5,7,6.5\nIntersection over Union (IoU),Measures the overlap between the predicted segments and the actual segments.,7.5,7,6.5,6,6.5,6,5.5,5.5,6,5.5\n\"\"\"\n\n# Read the data into a DataFrame\ndf = pd.read_csv(StringIO(data))\n# Set the index to 'Metric' for easier plotting\ndf.set_index('Metric', inplace=True)\n# Display the DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:35:55.720291Z","iopub.execute_input":"2024-09-02T09:35:55.720961Z","iopub.status.idle":"2024-09-02T09:35:55.747166Z","shell.execute_reply.started":"2024-09-02T09:35:55.720920Z","shell.execute_reply":"2024-09-02T09:35:55.746309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the 'Description' column as it's not numeric\ndf.drop(columns=['Description'], inplace=True)\n# Transpose the DataFrame for plotting\ndf_t = df.T","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:36:09.203521Z","iopub.execute_input":"2024-09-02T09:36:09.203889Z","iopub.status.idle":"2024-09-02T09:36:09.209903Z","shell.execute_reply.started":"2024-09-02T09:36:09.203853Z","shell.execute_reply":"2024-09-02T09:36:09.208901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14, 8))\nsns.set(style=\"whitegrid\")\ndf_t.plot(kind='bar', figsize=(14, 8), colormap='viridis')\nplt.title('Performance of SAM on All Images')\nplt.xlabel('Images')\nplt.ylabel('Scores')\nplt.legend(title='Metrics')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T09:36:59.946996Z","iopub.execute_input":"2024-09-02T09:36:59.947792Z","iopub.status.idle":"2024-09-02T09:37:00.487963Z","shell.execute_reply.started":"2024-09-02T09:36:59.947752Z","shell.execute_reply":"2024-09-02T09:37:00.487103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\n> * **Accuracy**: High accuracy (6.5-8.5/10) across images, even with a 50-mask limit.\n\n> * **Precision and Recall**: Effective at identifying relevant segments (Precision: 6-8, Recall: 7-9).\n\n> * **IoU**: Lower overlap accuracy (5.5-7.5), indicating boundary discrepancies.\n\n> * **Consistency**: Consistent performance across various image types, with slight struggles in low-contrast images.\n\n> * **Improvement Areas**: Enhance boundary precision and reduce false positives, considering the 50-mask limitation.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport rasterio\nimport os\nimport pandas as pd\n\n# Import SAM (Segment Anything Model) components\nfrom segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n\n# Load the pre-trained SAM model\nsam_checkpoint = \"/kaggle/input/segment-anything/pytorch/vit-h/1/model.pth\"  # Path to SAM model checkpoint\nmodel_type = \"vit_h\"  # Choose SAM model type: vit_h, vit_l, or vit_b\n\n# Register the SAM model and load weights\nsam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n\n# Set up device (GPU if available, otherwise CPU)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Check the number of available GPUs\nnum_gpus = torch.cuda.device_count()\n\n# Set device ids based on available GPUs\nif num_gpus > 1:\n    model = torch.nn.DataParallel(sam, device_ids=[i for i in range(num_gpus)]).to(device)\nelse:\n    model = sam.to(device)  \n\n# Initialize SAM's mask generator for automatic mask generation\nmask_generator = SamAutomaticMaskGenerator(sam)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:37:31.628619Z","iopub.execute_input":"2024-09-20T10:37:31.629665Z","iopub.status.idle":"2024-09-20T10:38:13.670567Z","shell.execute_reply.started":"2024-09-20T10:37:31.629619Z","shell.execute_reply":"2024-09-20T10:38:13.669600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to clear GPU memory after each iteration\ndef clear_gpu_memory():\n    torch.cuda.empty_cache()  # Clears the PyTorch cache\n    for obj in list(locals().values()):\n        if torch.is_tensor(obj):\n            del obj  # Deletes any tensors still in memory\n    torch.cuda.empty_cache()  # Clears again after deletion\n\n# Function to compute Intersection over Union (IoU)\ndef compute_iou(y_true, y_pred):\n    intersection = np.logical_and(y_true, y_pred)\n    union = np.logical_or(y_true, y_pred)\n    if np.sum(union) == 0:\n        return 1.0  # Perfect match or both empty\n    iou_score = np.sum(intersection) / np.sum(union)\n    return iou_score\n\n# Function to compute Dice Coefficient\ndef compute_dice(y_true, y_pred):\n    intersection = np.sum(y_true * y_pred)\n    if (np.sum(y_true) + np.sum(y_pred)) == 0:\n        return 1.0  # Perfect match or both empty\n    dice_score = (2 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n    return dice_score","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:39:02.016902Z","iopub.execute_input":"2024-09-20T10:39:02.018120Z","iopub.status.idle":"2024-09-20T10:39:02.026757Z","shell.execute_reply.started":"2024-09-20T10:39:02.018071Z","shell.execute_reply":"2024-09-20T10:39:02.025621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to process TIFF images and generate segmentation masks\ndef process_tiff_and_generate_masks(tif_file, mask_generator):\n    print(f\"Processing: {tif_file}\")\n    \n    # Open the TIFF file and read the first three bands (R, G, B)\n    with rasterio.open(tif_file) as dataset:\n        r = dataset.read(1)  # Red channel\n        g = dataset.read(2)  # Green channel\n        b = dataset.read(3)  # Blue channel\n    \n    # Stack the R, G, B bands to create an RGB image\n    rgb_image = np.stack([r, g, b], axis=-1)\n    \n    # Normalize the RGB image to the range [0, 255] for visualization\n    rgb_image = (255 * (rgb_image - np.min(rgb_image)) / (np.max(rgb_image) - np.min(rgb_image))).astype(np.uint8)\n    \n    # Generate masks using the SAM mask generator\n    masks = mask_generator.generate(rgb_image)\n    \n    # Sort the masks by their area size and select the top 100 largest masks\n    sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n    top_masks = sorted_masks[:100]  # Limit to top 100 largest masks\n\n    # Create a combined binary mask from the top masks\n    combined_mask = np.zeros((rgb_image.shape[0], rgb_image.shape[1]), dtype=np.uint8)\n    for mask_info in top_masks:\n        mask = mask_info['segmentation']\n        combined_mask[mask] = 1  # Set mask pixels to 1\n\n    return rgb_image, top_masks, combined_mask","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:39:03.082253Z","iopub.execute_input":"2024-09-20T10:39:03.082958Z","iopub.status.idle":"2024-09-20T10:39:03.092511Z","shell.execute_reply.started":"2024-09-20T10:39:03.082915Z","shell.execute_reply":"2024-09-20T10:39:03.091456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to visualize the generated segmentation masks\ndef show_output(rgb_image, top_masks, mask_file_path):\n    fig, axes = plt.subplots(1, 3, figsize=(24, 16))\n\n    # Display the original RGB image\n    axes[0].imshow(rgb_image)\n    axes[0].set_title(\"Original Image\")\n    axes[0].axis('off')  # Turn off the axes for a cleaner look\n\n    # Overlay the segmentation masks\n    overlay_image = rgb_image.copy()\n    for mask_info in top_masks:\n        mask = mask_info['segmentation']\n        color_mask = np.random.randint(0, 255, size=3)  # Random color for each mask\n        overlay_image[mask] = overlay_image[mask] * 0.5 + color_mask * 0.5\n\n    # Display the segmentation masks overlay\n    axes[1].imshow(overlay_image.astype(np.uint8))\n    axes[1].set_title(\"Segmentation Masks\")\n    axes[1].axis('off')\n\n    # Read and display the ground truth raster mask\n    with rasterio.open(mask_file_path) as src:\n        band1 = src.read(1)\n\n    axes[2].imshow(band1, cmap='gray')\n    axes[2].set_title(\"Ground Truth Raster Mask\")\n    axes[2].axis('off')\n\n    # Show the plot\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T10:39:03.690878Z","iopub.execute_input":"2024-09-20T10:39:03.691368Z","iopub.status.idle":"2024-09-20T10:39:03.702158Z","shell.execute_reply.started":"2024-09-20T10:39:03.691314Z","shell.execute_reply":"2024-09-20T10:39:03.700981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paths to the directories\nimage_directory = \"/kaggle/input/deforestation-detection-dataset/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/\"\nmask_directory = \"/kaggle/input/deforestation-detection-dataset/3_TRAINING_MASKS/MASK_16_GRID/\"\n\n# Initialize lists to store evaluation metrics\niou_scores = []\ndice_scores = []\nimage_filenames = []\n\n# Loop through the directory and process each .tif file\nfor filename in os.listdir(image_directory):\n    if filename.endswith(\".tif\"):  # Only process TIFF files\n        tif_file = os.path.join(image_directory, filename)\n        \n        # Process the image and generate masks\n        rgb_image, top_masks, combined_mask = process_tiff_and_generate_masks(tif_file, mask_generator)\n        \n        # Construct the ground truth mask filename\n        mask_filename = filename  # Assuming mask files have the same name as the image files\n        mask_file = os.path.join(mask_directory, mask_filename)\n\n        if os.path.exists(mask_file):\n            # Read the ground truth mask\n            with rasterio.open(mask_file) as mask_dataset:\n                ground_truth_mask = mask_dataset.read(1)\n\n            # Binarize the ground truth mask\n            ground_truth_mask = (ground_truth_mask > 0).astype(np.uint8)\n\n            # Ensure that combined_mask and ground_truth_mask have the same dimensions\n            if combined_mask.shape != ground_truth_mask.shape:\n                print(\"Resizing masks to match dimensions\")\n                combined_mask_resized = cv2.resize(combined_mask, (ground_truth_mask.shape[1], ground_truth_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n            else:\n                combined_mask_resized = combined_mask\n\n            # Compute evaluation metrics\n            iou_score = compute_iou(ground_truth_mask, combined_mask_resized)\n            dice_score = compute_dice(ground_truth_mask, combined_mask_resized)\n            \n            # Store metrics\n            iou_scores.append(iou_score)\n            dice_scores.append(dice_score)\n            image_filenames.append(filename)\n            \n            print(f\"IoU Score: {iou_score:.4f}\")\n            print(f\"Dice Score: {dice_score:.4f}\")\n\n            # Visualize the results\n            show_output(rgb_image, top_masks, mask_file)\n        else:\n            print(f\"Ground truth mask not found for {filename}\")\n            continue\n\n        # Clear GPU memory after processing each image\n        clear_gpu_memory()\n\n# Create a DataFrame to store the results\nresults_df = pd.DataFrame({\n    'Image': image_filenames,\n    'IoU': iou_scores,\n    'Dice': dice_scores\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:36:02.606062Z","iopub.execute_input":"2024-09-19T13:36:02.606936Z","iopub.status.idle":"2024-09-19T13:40:31.714797Z","shell.execute_reply.started":"2024-09-19T13:36:02.606894Z","shell.execute_reply":"2024-09-19T13:40:31.713837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Assuming results_df is already defined and contains 'IoU' and 'Dice' scores\n\n# Calculate average IoU and Dice scores\naverage_iou = results_df['IoU'].mean()\naverage_dice = results_df['Dice'].mean()\n\n# Plot IoU scores with average line\nplt.figure(figsize=(12, 6))\nplt.plot(results_df['Image'], results_df['IoU'], marker='o', label='IoU Score')\nplt.axhline(y=average_iou, color='red', linestyle='--', label=f'Average IoU: {average_iou:.4f}')\nplt.xticks(rotation=90)\nplt.xlabel('Image Filename')\nplt.ylabel('IoU Score')\nplt.title('IoU Scores for Segmentation')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Plot Dice scores with average line\nplt.figure(figsize=(12, 6))\nplt.plot(results_df['Image'], results_df['Dice'], marker='o', color='green', label='Dice Score')\nplt.axhline(y=average_dice, color='red', linestyle='--', label=f'Average Dice: {average_dice:.4f}')\nplt.xticks(rotation=90)\nplt.xlabel('Image Filename')\nplt.ylabel('Dice Score')\nplt.title('Dice Scores for Segmentation')\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T13:40:31.716518Z","iopub.execute_input":"2024-09-19T13:40:31.716875Z","iopub.status.idle":"2024-09-19T13:40:32.674792Z","shell.execute_reply.started":"2024-09-19T13:40:31.716837Z","shell.execute_reply":"2024-09-19T13:40:32.673849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to process TIFF images and generate segmentation masks\ndef process_tiff_and_generate_masks(tif_file, mask_generator):\n    print(f\"Processing: {tif_file}\")\n    \n    # Open the TIFF file and read the first three bands (R, G, B)\n    with rasterio.open(tif_file) as dataset:\n        r = dataset.read(1)  # Red channel\n        g = dataset.read(2)  # Green channel\n        b = dataset.read(3)  # Blue channel\n    \n    # Stack the R, G, B bands to create an RGB image\n    rgb_image = np.stack([r, g, b], axis=-1)\n    \n    # Normalize the RGB image to the range [0, 255] for visualization\n    rgb_image = (255 * (rgb_image - np.min(rgb_image)) / (np.max(rgb_image) - np.min(rgb_image))).astype(np.uint8)\n    \n    # Generate masks using the SAM mask generator\n    masks = mask_generator.generate(rgb_image)\n    \n    # Sort the masks by their area size and select the top 100 largest masks\n    sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n    top_masks = sorted_masks[:10000]  # Limit to top 100 largest masks\n\n    # Create a combined binary mask from the top masks\n    combined_mask = np.zeros((rgb_image.shape[0], rgb_image.shape[1]), dtype=np.uint8)\n    for mask_info in top_masks:\n        mask = mask_info['segmentation']\n        combined_mask[mask] = 1  # Set mask pixels to 1\n\n    return rgb_image, top_masks, combined_mask","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:07:57.787995Z","iopub.execute_input":"2024-09-20T11:07:57.788512Z","iopub.status.idle":"2024-09-20T11:07:57.799796Z","shell.execute_reply.started":"2024-09-20T11:07:57.788470Z","shell.execute_reply":"2024-09-20T11:07:57.798625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paths to the directories\nimage_directory = \"/kaggle/input/deforestation-detection-dataset/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/\"\nmask_directory = \"/kaggle/input/deforestation-detection-dataset/3_TRAINING_MASKS/MASK_16_GRID/\"\n\n# Initialize lists to store evaluation metrics\niou_scores = []\ndice_scores = []\nimage_filenames = []\n\n# Loop through the directory and process each .tif file\nfor filename in os.listdir(image_directory):\n    if filename.endswith(\".tif\"):  # Only process TIFF files\n        tif_file = os.path.join(image_directory, filename)\n        \n        # Process the image and generate masks\n        rgb_image, top_masks, combined_mask = process_tiff_and_generate_masks(tif_file, mask_generator)\n        \n        # Construct the ground truth mask filename\n        mask_filename = filename  # Assuming mask files have the same name as the image files\n        mask_file = os.path.join(mask_directory, mask_filename)\n\n        if os.path.exists(mask_file):\n            # Read the ground truth mask\n            with rasterio.open(mask_file) as mask_dataset:\n                ground_truth_mask = mask_dataset.read(1)\n\n            # Binarize the ground truth mask\n            ground_truth_mask = (ground_truth_mask > 0).astype(np.uint8)\n\n            # Ensure that combined_mask and ground_truth_mask have the same dimensions\n            if combined_mask.shape != ground_truth_mask.shape:\n                print(\"Resizing masks to match dimensions\")\n                combined_mask_resized = cv2.resize(combined_mask, (ground_truth_mask.shape[1], ground_truth_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n            else:\n                combined_mask_resized = combined_mask\n\n            # Compute evaluation metrics\n            iou_score = compute_iou(ground_truth_mask, combined_mask_resized)\n            dice_score = compute_dice(ground_truth_mask, combined_mask_resized)\n            \n            # Store metrics\n            iou_scores.append(iou_score)\n            dice_scores.append(dice_score)\n            image_filenames.append(filename)\n            \n            print(f\"IoU Score: {iou_score:.4f}\")\n            print(f\"Dice Score: {dice_score:.4f}\")\n\n            # Visualize the results\n            show_output(rgb_image, top_masks, mask_file)\n        else:\n            print(f\"Ground truth mask not found for {filename}\")\n            continue\n\n        # Clear GPU memory after processing each image\n        clear_gpu_memory()\n\n# Create a DataFrame to store the results\nresults_df = pd.DataFrame({\n    'Image': image_filenames,\n    'IoU': iou_scores,\n    'Dice': dice_scores\n})","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:07:58.940996Z","iopub.execute_input":"2024-09-20T11:07:58.941418Z","iopub.status.idle":"2024-09-20T11:12:42.805189Z","shell.execute_reply.started":"2024-09-20T11:07:58.941362Z","shell.execute_reply":"2024-09-20T11:12:42.804033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Assuming results_df is already defined and contains 'IoU' and 'Dice' scores\n\n# Calculate average IoU and Dice scores\naverage_iou = results_df['IoU'].mean()\naverage_dice = results_df['Dice'].mean()\n\n# Plot IoU scores with average line\nplt.figure(figsize=(12, 6))\nplt.plot(results_df['Image'], results_df['IoU'], marker='o', label='IoU Score')\nplt.axhline(y=average_iou, color='red', linestyle='--', label=f'Average IoU: {average_iou:.4f}')\nplt.xticks(rotation=90)\nplt.xlabel('Image Filename')\nplt.ylabel('IoU Score')\nplt.title('IoU Scores for Segmentation')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Plot Dice scores with average line\nplt.figure(figsize=(12, 6))\nplt.plot(results_df['Image'], results_df['Dice'], marker='o', color='green', label='Dice Score')\nplt.axhline(y=average_dice, color='red', linestyle='--', label=f'Average Dice: {average_dice:.4f}')\nplt.xticks(rotation=90)\nplt.xlabel('Image Filename')\nplt.ylabel('Dice Score')\nplt.title('Dice Scores for Segmentation')\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T11:12:42.807009Z","iopub.execute_input":"2024-09-20T11:12:42.807348Z","iopub.status.idle":"2024-09-20T11:12:43.935041Z","shell.execute_reply.started":"2024-09-20T11:12:42.807313Z","shell.execute_reply":"2024-09-20T11:12:43.934016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}